{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.6.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from tensorflow.python.layers.core import Dense\n",
    "from tensorflow.python.ops.rnn_cell_impl import _zero_state_tensors\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.getcwd()+\"/idebateextra.json\"\n",
    "Glove_path=os.getcwd()+\"/glove.6B.50d.txt\"\n",
    "\n",
    "def load_data(file_path):\n",
    "    with open(file_path) as file:\n",
    "        raw_data=file.read()\n",
    "        json_data=json.loads(raw_data)\n",
    "    dataframe=pd.DataFrame(columns=[\"text\",\"summary\"])\n",
    "    for i in json_data:\n",
    "        text_summary_pair={}\n",
    "        text=\" \"\n",
    "        for x in i[\"_argument_sentences\"]:\n",
    "            text=text+i[\"_argument_sentences\"][x].lower()\n",
    "            #probably we can get rid of stopping word and punctuaton for input\n",
    "        text_summary_pair[\"text\"]=text\n",
    "        text_summary_pair[\"summary\"]=i[\"_claim\"]\n",
    "        dataframe=dataframe.append(text_summary_pair,ignore_index=True)#append doesn't happen in place\n",
    "    return dataframe\n",
    "##########################################\n",
    "dataframe=load_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td></td>\n",
       "      <td>It is a power that state governors already have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>imperialism and colonisation is one of the gr...</td>\n",
       "      <td>Ethnic borders erase a wrong of history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>an amnesty by its very definition is letting ...</td>\n",
       "      <td>An amnesty rewards law breakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>in response to an ever faster news agenda , p...</td>\n",
       "      <td>In an age of declining journalistic standards,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>what is needed for the eurozone to flourish i...</td>\n",
       "      <td>Political union is necessary for Eurozone reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "4348                                                      \n",
       "3494   imperialism and colonisation is one of the gr...   \n",
       "2050   an amnesty by its very definition is letting ...   \n",
       "1172   in response to an ever faster news agenda , p...   \n",
       "288    what is needed for the eurozone to flourish i...   \n",
       "\n",
       "                                                summary  \n",
       "4348    It is a power that state governors already have  \n",
       "3494            Ethnic borders erase a wrong of history  \n",
       "2050                    An amnesty rewards law breakers  \n",
       "1172  In an age of declining journalistic standards,...  \n",
       "288   Political union is necessary for Eurozone reco...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n",
      "Done. 400000  words loaded!\n"
     ]
    }
   ],
   "source": [
    "def loadGloveModel(gloveFile):\n",
    "    print(\"Loading Glove Model\")\n",
    "    f = open(gloveFile,'r')\n",
    "    model = {}\n",
    "    for line in f:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "##################################################\n",
    "embeddings_index=loadGloveModel(Glove_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(count_dict, text):\n",
    "    '''Count the number of occurrences of each word in a set of text'''\n",
    "    for sentence in text:\n",
    "        for word in sentence.split():\n",
    "            if word not in count_dict:\n",
    "                count_dict[word] = 1\n",
    "            else:\n",
    "                count_dict[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 38819\n"
     ]
    }
   ],
   "source": [
    "word_counts = {}\n",
    "count_words(word_counts, dataframe[\"text\"])\n",
    "count_words(word_counts, dataframe[\"summary\"])\n",
    "print(\"Size of Vocabulary:\", len(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words missing from glove: 1746\n",
      "Percent of words that are missing from vocabulary: 4.5%\n"
     ]
    }
   ],
   "source": [
    "missing_words = 0\n",
    "threshold = 2\n",
    "\n",
    "for word, count in word_counts.items():\n",
    "    if count > threshold:\n",
    "        if word not in embeddings_index:\n",
    "            missing_words += 1\n",
    "            \n",
    "missing_ratio = round(missing_words/len(word_counts),4)*100\n",
    "            \n",
    "print(\"Number of words missing from glove:\", missing_words)\n",
    "print(\"Percent of words that are missing from vocabulary: {}%\".format(missing_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique words: 38819\n",
      "Number of words we will use: 30800\n",
      "Percent of words we will use: 79.34%\n"
     ]
    }
   ],
   "source": [
    "vocab_to_int = {} \n",
    "\n",
    "value = 0\n",
    "for word, count in word_counts.items():\n",
    "    if count >= threshold or word in embeddings_index:\n",
    "        vocab_to_int[word] = value\n",
    "        value += 1\n",
    "\n",
    "# Special tokens that will be added to our vocab\n",
    "codes = [\"<UNK>\",\"<PAD>\",\"<EOS>\",\"<GO>\"]   \n",
    "\n",
    "# Add codes to vocab\n",
    "for code in codes:\n",
    "    vocab_to_int[code] = len(vocab_to_int)\n",
    "\n",
    "# Dictionary to convert integers to words\n",
    "int_to_vocab = {}\n",
    "for word, value in vocab_to_int.items():\n",
    "    int_to_vocab[value] = word\n",
    "\n",
    "usage_ratio = round(len(vocab_to_int) / len(word_counts),4)*100\n",
    "\n",
    "print(\"Total number of unique words:\", len(word_counts))\n",
    "print(\"Number of words we will use:\", len(vocab_to_int))\n",
    "print(\"Percent of words we will use: {}%\".format(usage_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30800\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "nb_words = len(vocab_to_int)\n",
    "\n",
    "# Create matrix with default values of zero\n",
    "word_embedding_matrix = np.zeros((nb_words, embedding_dim), dtype=np.float32)\n",
    "for word, i in vocab_to_int.items():\n",
    "    if word in embeddings_index:\n",
    "        word_embedding_matrix[i] = embeddings_index[word]\n",
    "    else:\n",
    "        # If word not in CN, create a random embedding for it\n",
    "        new_embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n",
    "        embeddings_index[word] = new_embedding\n",
    "        word_embedding_matrix[i] = new_embedding\n",
    "\n",
    "# Check if value matches len(vocab_to_int)\n",
    "print(len(word_embedding_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_ints(text, word_count, unk_count, eos=False):\n",
    "    '''Convert words in text to an integer.\n",
    "       If word is not in vocab_to_int, use UNK's integer.\n",
    "       Total the number of words and UNKs.\n",
    "       Add EOS token to the end of texts'''\n",
    "    ints = []\n",
    "    for sentence in text:\n",
    "        sentence_ints = []\n",
    "        for word in sentence.split():\n",
    "            word_count += 1\n",
    "            if word in vocab_to_int:\n",
    "                sentence_ints.append(vocab_to_int[word])\n",
    "            else:\n",
    "                sentence_ints.append(vocab_to_int[\"<UNK>\"])\n",
    "                unk_count += 1\n",
    "        if eos:\n",
    "            sentence_ints.append(vocab_to_int[\"<EOS>\"])\n",
    "        ints.append(sentence_ints)\n",
    "    return ints, word_count, unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_summaries=dataframe[\"summary\"]\n",
    "clean_texts=dataframe[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in headlines: 964675\n",
      "Total number of UNKs in headlines: 8023\n",
      "Percent of words that are UNK: 0.83%\n"
     ]
    }
   ],
   "source": [
    "word_count = 0\n",
    "unk_count = 0\n",
    "\n",
    "int_summaries, word_count, unk_count = convert_to_ints(clean_summaries, word_count, unk_count)\n",
    "int_texts, word_count, unk_count = convert_to_ints(clean_texts, word_count, unk_count, eos=True)\n",
    "\n",
    "unk_percent = round(unk_count/word_count,4)*100\n",
    "\n",
    "print(\"Total number of words in headlines:\", word_count)\n",
    "print(\"Total number of UNKs in headlines:\", unk_count)\n",
    "print(\"Percent of words that are UNK: {}%\".format(unk_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries:\n",
      "            counts\n",
      "count  4351.000000\n",
      "mean      9.891979\n",
      "std       5.821625\n",
      "min       1.000000\n",
      "25%       6.000000\n",
      "50%       9.000000\n",
      "75%      12.000000\n",
      "max      47.000000\n",
      "\n",
      "Texts:\n",
      "            counts\n",
      "count  4351.000000\n",
      "mean    212.821420\n",
      "std     105.603906\n",
      "min       1.000000\n",
      "25%     143.000000\n",
      "50%     192.000000\n",
      "75%     256.000000\n",
      "max    1207.000000\n"
     ]
    }
   ],
   "source": [
    "lengths_summaries = create_lengths(int_summaries)\n",
    "lengths_texts = create_lengths(int_texts)\n",
    "\n",
    "print(\"Summaries:\")\n",
    "print(lengths_summaries.describe())\n",
    "print()\n",
    "print(\"Texts:\")\n",
    "print(lengths_texts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333.0\n",
      "400.0\n",
      "592.0\n"
     ]
    }
   ],
   "source": [
    "print(np.percentile(lengths_texts.counts, 90))\n",
    "print(np.percentile(lengths_texts.counts, 95))\n",
    "print(np.percentile(lengths_texts.counts, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0\n",
      "21.0\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "print(np.percentile(lengths_summaries.counts, 90))\n",
    "print(np.percentile(lengths_summaries.counts, 95))\n",
    "print(np.percentile(lengths_summaries.counts, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unk_counter(sentence):\n",
    "    '''Counts the number of time UNK appears in a sentence.'''\n",
    "    unk_count = 0\n",
    "    for word in sentence:\n",
    "        if word == vocab_to_int[\"<UNK>\"]:\n",
    "            unk_count += 1\n",
    "    return unk_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4049\n",
      "4049\n"
     ]
    }
   ],
   "source": [
    "sorted_summaries = []\n",
    "sorted_texts = []\n",
    "max_text_length = 400\n",
    "max_summary_length = 30\n",
    "min_length = 2\n",
    "unk_text_limit = 30\n",
    "unk_summary_limit = 5\n",
    "\n",
    "for length in range(min(lengths_texts.counts), max_text_length): \n",
    "    for count, words in enumerate(int_summaries):\n",
    "        if (len(int_summaries[count]) >= min_length and\n",
    "            len(int_summaries[count]) <= max_summary_length and\n",
    "            len(int_texts[count]) >= min_length and\n",
    "            unk_counter(int_summaries[count]) <= unk_summary_limit and\n",
    "            unk_counter(int_texts[count]) <= unk_text_limit and\n",
    "            length == len(int_texts[count])\n",
    "           ):\n",
    "            sorted_summaries.append(int_summaries[count])\n",
    "            sorted_texts.append(int_texts[count])\n",
    "        \n",
    "# Compare lengths to ensure they match\n",
    "print(len(sorted_summaries))\n",
    "print(len(sorted_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    '''Create palceholders for inputs to the model'''\n",
    "    \n",
    "    input_data = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    summary_length = tf.placeholder(tf.int32, (None,), name='summary_length')\n",
    "    max_summary_length = tf.reduce_max(summary_length, name='max_dec_len')\n",
    "    text_length = tf.placeholder(tf.int32, (None,), name='text_length')\n",
    "\n",
    "    return input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_encoding_input(target_data, vocab_to_int, batch_size):\n",
    "    '''Remove the last word id from each batch and concat the <GO> to the begining of each batch'''\n",
    "    \n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    dec_input = tf.concat([tf.fill([batch_size, 1], vocab_to_int['<GO>']), ending], 1)\n",
    "\n",
    "    return dec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_layer(rnn_size, sequence_length, num_layers, rnn_inputs, keep_prob):\n",
    "    '''Create the encoding layer'''\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope('encoder_{}'.format(layer)):\n",
    "            cell_fw = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_fw = tf.contrib.rnn.DropoutWrapper(cell_fw, \n",
    "                                                    input_keep_prob = keep_prob)\n",
    "\n",
    "            cell_bw = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                              initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            cell_bw = tf.contrib.rnn.DropoutWrapper(cell_bw, \n",
    "                                                    input_keep_prob = keep_prob)\n",
    "\n",
    "            enc_output, enc_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, \n",
    "                                                                    cell_bw, \n",
    "                                                                    rnn_inputs,\n",
    "                                                                    sequence_length,\n",
    "                                                                    dtype=tf.float32)\n",
    "    # Join outputs since we are using a bidirectional RNN\n",
    "    enc_output = tf.concat(enc_output,2)\n",
    "    \n",
    "    return enc_output, enc_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_decoding_layer(dec_embed_input, summary_length, dec_cell, initial_state, output_layer, \n",
    "                            vocab_size, max_summary_length):\n",
    "    '''Create the training logits'''\n",
    "    \n",
    "    training_helper = tf.contrib.seq2seq.TrainingHelper(inputs=dec_embed_input,\n",
    "                                                        sequence_length=summary_length,\n",
    "                                                        time_major=False)\n",
    "\n",
    "    training_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                       training_helper,\n",
    "                                                       initial_state,\n",
    "                                                       output_layer) \n",
    "\n",
    "    training_logits, _,_ = tf.contrib.seq2seq.dynamic_decode(training_decoder,\n",
    "                                                           output_time_major=False,\n",
    "                                                           impute_finished=True,\n",
    "                                                           maximum_iterations=max_summary_length)\n",
    "    return training_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_decoding_layer(embeddings, start_token, end_token, dec_cell, initial_state, output_layer,\n",
    "                             max_summary_length, batch_size):\n",
    "    '''Create the inference logits'''\n",
    "    \n",
    "    start_tokens = tf.tile(tf.constant([start_token], dtype=tf.int32), [batch_size], name='start_tokens')\n",
    "    \n",
    "    inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(embeddings,\n",
    "                                                                start_tokens,\n",
    "                                                                end_token)\n",
    "                \n",
    "    inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell,\n",
    "                                                        inference_helper,\n",
    "                                                        initial_state,\n",
    "                                                        output_layer)\n",
    "                \n",
    "    inference_logits, _ ,_= tf.contrib.seq2seq.dynamic_decode(inference_decoder,\n",
    "                                                            output_time_major=False,\n",
    "                                                            impute_finished=True,\n",
    "                                                            maximum_iterations=max_summary_length)\n",
    "    \n",
    "    return inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding_layer(dec_embed_input, embeddings, enc_output, enc_state, vocab_size, text_length, summary_length, \n",
    "                   max_summary_length, rnn_size, vocab_to_int, keep_prob, batch_size, num_layers):\n",
    "    '''Create the decoding cell and attention for the training and inference decoding layers'''\n",
    "    \n",
    "    for layer in range(num_layers):\n",
    "        with tf.variable_scope('decoder_{}'.format(layer)):\n",
    "            lstm = tf.contrib.rnn.LSTMCell(rnn_size,\n",
    "                                           initializer=tf.random_uniform_initializer(-0.1, 0.1, seed=2))\n",
    "            dec_cell = tf.contrib.rnn.DropoutWrapper(lstm, \n",
    "                                                     input_keep_prob = keep_prob)\n",
    "    \n",
    "    output_layer = Dense(vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "    \n",
    "    attn_mech = tf.contrib.seq2seq.BahdanauAttention(rnn_size,\n",
    "                                                  enc_output,\n",
    "                                                  text_length,\n",
    "                                                  normalize=False,\n",
    "                                                  name='BahdanauAttention')\n",
    "\n",
    "    dec_cell = tf.contrib.seq2seq.AttentionWrapper(dec_cell,\n",
    "                                                   attn_mech,\n",
    "                                                   rnn_size)\n",
    "            \n",
    "    \n",
    "    initial_state = dec_cell.zero_state(dtype=tf.float32, batch_size=batch_size)\n",
    "    initial_state = initial_state.clone(cell_state=enc_state[0])\n",
    "    with tf.variable_scope(\"decode\"):\n",
    "        training_logits = training_decoding_layer(dec_embed_input, \n",
    "                                                  summary_length, \n",
    "                                                  dec_cell, \n",
    "                                                  initial_state,\n",
    "                                                  output_layer,\n",
    "                                                  vocab_size, \n",
    "                                                  max_summary_length)\n",
    "    with tf.variable_scope(\"decode\", reuse=True):\n",
    "        inference_logits = inference_decoding_layer(embeddings,  \n",
    "                                                    vocab_to_int['<GO>'], \n",
    "                                                    vocab_to_int['<EOS>'],\n",
    "                                                    dec_cell, \n",
    "                                                    initial_state, \n",
    "                                                    output_layer,\n",
    "                                                    max_summary_length,\n",
    "                                                    batch_size)\n",
    "\n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, text_length, summary_length, max_summary_length, \n",
    "                  vocab_size, rnn_size, num_layers, vocab_to_int, batch_size):\n",
    "    '''Use the previous functions to create the training and inference logits'''\n",
    "    \n",
    "    # Use Numberbatch's embeddings and the newly created ones as our embeddings\n",
    "    embeddings = word_embedding_matrix\n",
    "    \n",
    "    enc_embed_input = tf.nn.embedding_lookup(embeddings, input_data)\n",
    "    enc_output, enc_state = encoding_layer(rnn_size, text_length, num_layers, enc_embed_input, keep_prob)\n",
    "    \n",
    "    dec_input = process_encoding_input(target_data, vocab_to_int, batch_size)\n",
    "    dec_embed_input = tf.nn.embedding_lookup(embeddings, dec_input)\n",
    "    \n",
    "    training_logits, inference_logits  = decoding_layer(dec_embed_input, \n",
    "                                                        embeddings,\n",
    "                                                        enc_output,\n",
    "                                                        enc_state, \n",
    "                                                        vocab_size, \n",
    "                                                        text_length, \n",
    "                                                        summary_length, \n",
    "                                                        max_summary_length,\n",
    "                                                        rnn_size, \n",
    "                                                        vocab_to_int, \n",
    "                                                        keep_prob, \n",
    "                                                        batch_size,\n",
    "                                                        num_layers)\n",
    "    \n",
    "    return training_logits, inference_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [vocab_to_int['<PAD>']] * (max_sentence - len(sentence)) for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(summaries, texts, batch_size):\n",
    "    \"\"\"Batch summaries, texts, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(texts)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        summaries_batch = summaries[start_i:start_i + batch_size]\n",
    "        texts_batch = texts[start_i:start_i + batch_size]\n",
    "        pad_summaries_batch = np.array(pad_sentence_batch(summaries_batch))\n",
    "        pad_texts_batch = np.array(pad_sentence_batch(texts_batch))\n",
    "        \n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_summaries_lengths = []\n",
    "        for summary in pad_summaries_batch:\n",
    "            pad_summaries_lengths.append(len(summary))\n",
    "        \n",
    "        pad_texts_lengths = []\n",
    "        for text in pad_texts_batch:\n",
    "            pad_texts_lengths.append(len(text))\n",
    "        \n",
    "        yield pad_summaries_batch, pad_texts_batch, pad_summaries_lengths, pad_texts_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Hyperparameters\n",
    "epochs = 30\n",
    "batch_size = 64\n",
    "rnn_size = 256\n",
    "num_layers = 1\n",
    "learning_rate = 0.01\n",
    "keep_probability = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is built.\n"
     ]
    }
   ],
   "source": [
    "train_graph = tf.Graph()\n",
    "# Set the graph to default to ensure that it is ready for training\n",
    "with train_graph.as_default():\n",
    "    \n",
    "    # Load the model inputs    \n",
    "    input_data, targets, lr, keep_prob, summary_length, max_summary_length, text_length = model_inputs()\n",
    "\n",
    "    # Create the training and inference logits\n",
    "    training_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                      targets, \n",
    "                                                      keep_prob,   \n",
    "                                                      text_length,\n",
    "                                                      summary_length,\n",
    "                                                      max_summary_length,\n",
    "                                                      len(vocab_to_int)+1,\n",
    "                                                      rnn_size, \n",
    "                                                      num_layers, \n",
    "                                                      vocab_to_int,\n",
    "                                                      batch_size)\n",
    "    \n",
    "    # Create tensors for the training logits and inference logits\n",
    "    training_logits = tf.identity(training_logits.rnn_output, 'logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "    \n",
    "    # Create the weights for sequence_loss\n",
    "    masks = tf.sequence_mask(summary_length, max_summary_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -5., 5.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n",
    "print(\"Graph is built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1/30 Batch    2/63 - Loss: 17.006, Seconds: 6.66\n",
      "Epoch   1/30 Batch    4/63 - Loss:  7.214, Seconds: 7.48\n",
      "Epoch   1/30 Batch    6/63 - Loss:  5.672, Seconds: 8.41\n",
      "Epoch   1/30 Batch    8/63 - Loss:  3.857, Seconds: 8.17\n",
      "Epoch   1/30 Batch   10/63 - Loss:  3.225, Seconds: 6.93\n",
      "Epoch   1/30 Batch   12/63 - Loss:  2.913, Seconds: 8.58\n",
      "Epoch   1/30 Batch   14/63 - Loss:  3.651, Seconds: 6.62\n",
      "Epoch   1/30 Batch   16/63 - Loss:  3.405, Seconds: 6.93\n",
      "Epoch   1/30 Batch   18/63 - Loss:  2.783, Seconds: 9.92\n",
      "Epoch   1/30 Batch   20/63 - Loss:  2.795, Seconds: 9.15\n",
      "Average loss for this update: 5.252\n",
      "New Record!\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "NodeDef expected inputs 'int32, int32' do not match 0 inputs specified; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>; NodeDef: max_dec_len_1 = Max[T=DT_INT32, Tidx=DT_INT32, _output_shapes=[[]], keep_dims=false]()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1331\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1391\u001b[0m           tf_session.TF_ExtendGraph(self._session,\n\u001b[0;32m-> 1392\u001b[0;31m                                     graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1393\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: NodeDef expected inputs 'int32, int32' do not match 0 inputs specified; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>; NodeDef: max_dec_len_1 = Max[T=DT_INT32, Tidx=DT_INT32, _output_shapes=[[]], keep_dims=false]()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-0eb5b2cd4157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m                     \u001b[0mstop_early\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1652\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1653\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1655\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m           self._build_eager(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: NodeDef expected inputs 'int32, int32' do not match 0 inputs specified; Op<name=Max; signature=input:T, reduction_indices:Tidx -> output:T; attr=keep_dims:bool,default=false; attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=Tidx:type,default=DT_INT32,allowed=[DT_INT32, DT_INT64]>; NodeDef: max_dec_len_1 = Max[T=DT_INT32, Tidx=DT_INT32, _output_shapes=[[]], keep_dims=false]()"
     ]
    }
   ],
   "source": [
    "learning_rate_decay = 0.95\n",
    "min_learning_rate = 0.0001\n",
    "display_step = 2 # Check training loss after every 20 batches\n",
    "stop_early = 0 \n",
    "stop = 3 # If the update loss does not decrease in 3 consecutive update checks, stop training\n",
    "per_epoch = 3 # Make 3 update checks per epoch\n",
    "update_check = (len(sorted_texts)//batch_size//per_epoch)-1\n",
    "\n",
    "\n",
    "update_loss = 0 \n",
    "batch_loss = 0\n",
    "summary_update_loss = [] # Record the update losses for saving improvements in the model\n",
    "loss_list_bi_withatt=[]\n",
    "checkpoint = \"./idebate_with_attention_singlelayer.ckpt\" \n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # If we want to continue training a previous session\n",
    "    #loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    #loader.restore(sess, checkpoint)\n",
    "    \n",
    "    for epoch_i in range(1, epochs+1):\n",
    "        update_loss = 0\n",
    "        batch_loss = 0\n",
    "        for batch_i, (summaries_batch, texts_batch, summaries_lengths, texts_lengths) in enumerate(\n",
    "                get_batches(sorted_summaries, sorted_texts, batch_size)):\n",
    "            start_time = time.time()\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: texts_batch,\n",
    "                 targets: summaries_batch,\n",
    "                 lr: learning_rate,\n",
    "                 summary_length: summaries_lengths,\n",
    "                 text_length: texts_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "            batch_loss += loss\n",
    "            update_loss += loss\n",
    "            end_time = time.time()\n",
    "            batch_time = end_time - start_time\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                loss_list_bi_withatt.append(batch_loss / display_step)\n",
    "                print('Epoch {:>3}/{} Batch {:>4}/{} - Loss: {:>6.3f}, Seconds: {:>4.2f}'\n",
    "                      .format(epoch_i,\n",
    "                              epochs, \n",
    "                              batch_i, \n",
    "                              len(sorted_texts) // batch_size, \n",
    "                              batch_loss / display_step, \n",
    "                              batch_time*display_step))\n",
    "                batch_loss = 0\n",
    "\n",
    "            if batch_i % update_check == 0 and batch_i > 0:\n",
    "                print(\"Average loss for this update:\", round(update_loss/update_check,3))\n",
    "                summary_update_loss.append(update_loss)\n",
    "                \n",
    "                # If the update loss is at a new minimum, save the model\n",
    "                if update_loss <= min(summary_update_loss):\n",
    "                    print('New Record!') \n",
    "                    stop_early = 0\n",
    "                    saver = tf.train.Saver() \n",
    "                    saver.save(sess, checkpoint)\n",
    "\n",
    "                else:\n",
    "                    print(\"No Improvement.\")\n",
    "                    stop_early += 1\n",
    "                    if stop_early == stop:\n",
    "                        break\n",
    "                update_loss = 0\n",
    "            \n",
    "                    \n",
    "        # Reduce learning rate, but not below its minimum value\n",
    "        learning_rate *= learning_rate_decay\n",
    "        if learning_rate < min_learning_rate:\n",
    "            learning_rate = min_learning_rate\n",
    "        \n",
    "        if stop_early == stop:\n",
    "            print(\"Stopping Training.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_seq(text):\n",
    "    '''Prepare the text for the model'''\n",
    "    return [vocab_to_int.get(word, vocab_to_int['<UNK>']) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = np.random.randint(0,len(clean_texts))\n",
    "input_sentence = clean_texts[random]\n",
    "expected_summary=clean_summaries[random]\n",
    "text = text_to_seq(clean_texts[random])\n",
    "\n",
    "checkpoint = \"./idebate_with_attention_singlelayer.ckpt\"\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(checkpoint + '.meta')\n",
    "    loader.restore(sess, checkpoint)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    text_length = loaded_graph.get_tensor_by_name('text_length:0')\n",
    "    summary_length = loaded_graph.get_tensor_by_name('summary_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "    \n",
    "    #Multiply by batch_size to match the model's input parameters\n",
    "    answer_logits = sess.run(logits, {input_data: [text]*batch_size, \n",
    "                                      summary_length: [np.random.randint(5,8)], \n",
    "                                      text_length: [len(text)]*batch_size,\n",
    "                                      keep_prob: 1.0})[0] \n",
    "\n",
    "# Remove the padding from the tweet\n",
    "pad = vocab_to_int[\"<PAD>\"] \n",
    "\n",
    "print('\\nText')\n",
    "#print('  Word Ids:    {}'.format([i for i in text]))\n",
    "print(\" \"+\" \".join([int_to_vocab[i] for i in text]))\n",
    "print('\\nExpected Summary:')\n",
    "print(\" \"+expected_summary)\n",
    "\n",
    "print('\\nPredicted Summary:')\n",
    "#print('  Word Ids:       {}'.format([i for i in answer_logits if i != pad]))\n",
    "print(\" \"+\" \".join([int_to_vocab[i] for i in answer_logits if i != pad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a207da6d8>]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_list_bi_withatt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
